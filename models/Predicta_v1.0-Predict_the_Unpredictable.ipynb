{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the datasets\n",
    "historical_weather = pd.read_csv('../artfacts/historical_weather.csv')\n",
    "sample_submission = pd.read_csv('../artfacts/sample_submission.csv')\n",
    "submission_key = pd.read_csv('../artfacts/submission_key.csv')\n",
    "\n",
    "# Handle missing values using interpolation\n",
    "historical_weather.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Generate date-based features\n",
    "historical_weather['date'] = pd.to_datetime(historical_weather['date'])\n",
    "historical_weather['year'] = historical_weather['date'].dt.year\n",
    "historical_weather['month'] = historical_weather['date'].dt.month\n",
    "historical_weather['day'] = historical_weather['date'].dt.day\n",
    "historical_weather['day_of_week'] = historical_weather['date'].dt.dayofweek\n",
    "\n",
    "# Normalize the temperature data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "historical_weather[['avg_temp_c']] = scaler.fit_transform(historical_weather[['avg_temp_c']])\n",
    "\n",
    "# Function to create sequences of data for LSTM input\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(data[i+seq_length])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "# Prepare the data for LSTM model\n",
    "sequence_length = 30\n",
    "unique_city_ids = historical_weather['city_id'].unique()\n",
    "\n",
    "# Create a DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame(columns=['submission_ID', 'avg_temp_c'])\n",
    "\n",
    "# Iterate through each city\n",
    "for city_id in unique_city_ids:\n",
    "    city_data = historical_weather[historical_weather['city_id'] == city_id]['avg_temp_c'].values\n",
    "\n",
    "    if len(city_data) < sequence_length:\n",
    "        print(f\"Not enough data points to create sequences for city {city_id}.\")\n",
    "        continue\n",
    "\n",
    "    X, y = create_sequences(city_data, sequence_length)\n",
    "\n",
    "    # Split into training and test sets\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Reshape the input to be 3D (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(sequence_length, 1)))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "    # Prepare predictions for the first week of 2019\n",
    "    first_week_2019_dates = pd.date_range(start='2019-01-01', end='2019-01-07')\n",
    "    first_week_predictions = []\n",
    "\n",
    "    # Use the last sequence from the training data to start the prediction\n",
    "    last_sequence = city_data[-sequence_length:]\n",
    "\n",
    "    for date in first_week_2019_dates:\n",
    "        # Predict the next value\n",
    "        last_sequence_reshaped = np.reshape(last_sequence, (1, sequence_length, 1))\n",
    "        next_prediction = model.predict(last_sequence_reshaped)\n",
    "        next_prediction_rescaled = scaler.inverse_transform(next_prediction)\n",
    "        first_week_predictions.append(next_prediction_rescaled[0][0])\n",
    "        \n",
    "        # Update the sequence with the new prediction\n",
    "        last_sequence = np.append(last_sequence[1:], next_prediction)\n",
    "\n",
    "    # Create a DataFrame for the city's predictions\n",
    "    city_submission_key = submission_key[submission_key['city_id'] == city_id].copy()\n",
    "    city_submission_key['avg_temp_c'] = first_week_predictions\n",
    "\n",
    "    # Append the city's predictions to the overall predictions DataFrame\n",
    "    predictions_df = pd.concat([predictions_df, city_submission_key[['submission_ID', 'avg_temp_c']]], ignore_index=True)\n",
    "\n",
    "# Merge predictions with sample_submission to create the final submission file\n",
    "final_submission = sample_submission.drop(columns=['avg_temp_c']).merge(predictions_df, on='submission_ID', how='left')\n",
    "\n",
    "# Save to CSV\n",
    "final_submission.to_csv('../artifacts/sample_submission.csv', index=False)\n",
    "print(\"Submission file saved as sample_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
